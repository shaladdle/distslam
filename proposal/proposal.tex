\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{graphicx}

% Always place footnotes at the bottom of the page
\usepackage[bottom]{footmisc}

\title{
15-780 Final Project Proposal \\ 
Distributed Simultaneous Localization And Mapping \\
}

\author{Adam Wright, Nathan Slobody, Tim Kuehn}

\begin{document}

\maketitle

\section{Introduction}

Robot perception is an important requirement for intelligent autonomous robots. For a robot to be able to use a search technique like $A*$ to find a path through an environment, or use some kind of planning to execute that path, the robot must first have a map of its environment. Some applications of robotics, such as search and rescue or indoor fire fighting do not have the luxury of having an accurate map beforehand. Simultaneous Localization And Mapping (SLAM) techniques, which build maps based only on sensor measurements, allow autonomous robots in these applications to succeed. Some applications, such as search and rescue, would benefit from using multiple robots to cover a wide area quickly. 

In this project, we will study robot perception by learning about and implementing multi-robot Simultaneous Localization And Mapping (SLAM). In particular we will focus on how robots share and combine their data and local maps to produce a single map of the environment all robots have explored thus far. Our goal is to implement a technique that does not add significant computing burden to the single-robot SLAM algorithm.

\section{Implementation}

Professor Veloso has agreed to provide us with two iRobot Create-based robots from her lab. We will use some simple method of landmark identification such as touch sensors using an iRobot Create bumper or vision along with an easily recognizable landmarks such as April tags. We can use these sensors along with the odometry from the Create to get all the sensor measurements we need to perform SLAM. 

So far, we have found some techniques for multi-robot SLAM in the literature based off of Sparse Extended Information Filters (Thrun, \cite{thrun2003}) and Constrained Factor Graphs (Cunningham, \cite{cunningham2010}). After reviewing these techniques and any others we can find, we will choose one and implement it. Cunningham's paper mentions a naive (inefficient) approach in which robots merely share all of their sensor data with all other robots. Some version of this naive approach will be a good starting point for getting communication working, and can serve as a benchmark for comparing later versions of our algorithm that are more efficient.

One possible focus for multi-robot SLAM is robustness and reliability, however we will assume that robots can always communicate with each other and the connection does not drop out. With this assumption, we are free to focus on integrating data from each robot efficiently to produce a single map.

\section{Goals}

As of now, we plan to investigate the pros and cons of multi-robot SLAM by answering some specific questions:

\begin{itemize}
    \item What should the starting conditions be? Do the robots need to know their initial locations with high precision/accuracy for this to work?

    \item Does having multiple robots perform SLAM on slightly overlapping areas produce good quality maps in less time? How does this compare to a single robot?

    \item How much more accuracy can we get from multiple robots mapping out heavily overlapping areas at the same time?

\end{itemize}

\section*{Project Plan}

\paragraph{75\%}
\begin{itemize}
    \item Ascertain CreBot capabilities: what sensors are included (bump, rangefinder, vision, etc), what onboard computing power is available, and what storage and communication facilities can be used.
    \item Become familiar with existing literature and research on SLAM, probabilistic tools such as Kalman and particle filters, and distributed / cooperative robotics.
    \item Determine how landmarks will be represented: april tags, something more sophisticated with feature extraction by sensors, or something as simple as possible with bump sensors.
        \begin{itemize}
            \item If using april tags, become familiar with their identification vis-a-vis the available sensors
        \end{itemize}
    \item Set up a testing location for the robots to map - either an artificial maze, a room in Gates Hillman Center, or another area.
    \item Learn or write any necessary control, navigation, communication or systems software for working with the robots.
    \item Write a simple navigation algorithm for the robot to decide where to go / in what order to traverse the area.
    \item Write a working SLAM implementation for a single robot.
\end{itemize}

\paragraph{100\%}

\begin{itemize}
    \item Work out systems programming details of information sharing between two robots.
    \item Decide how two robots will merge their maps (e.g. when they have both seen two of the same landmarks, or when they find that they are next to each other somehow).
    \item Get a potentially naive distributed SLAM implementation working for two robots.
\end{itemize}

\paragraph{125\%}
\begin{itemize}
    \item Iron out any wrinkles in the basic distributed SLAM implementation and get a more sophisticated/reliable/faster version working
    \item Write a more efficient navigation algorithm for the robot to decide where to go / in what order to traverse the area.
    \item Possibly add an additional robot or two to ascertain the impact on speed and efficiency.
\end{itemize}

\begin{thebibliography}{12}
    \bibitem{thrun2005}
        S. Thrun, W. Burgard, and D. Fox, \emph{Probabilistic Robotics}, MIT Press, 2005.

    \bibitem{thrun2003}
        S. Thrun and Y. Liu, ``Multi-Robot SLAM with Sparse Extended Information Filters'', \emph{Proceedings of the 11th International Symposium of Robotics Research (ISRR'03)}, 2003.

    \bibitem{cunningham2010}
        A. Cunningham, M. Paluri, and F. Dellaert, ``DDF-SAM: Fully Distributed SLAM using Constrained Factor Graphs'', \emph{International Conference on Intelligent Robots and Systems (IROS)}, 2010.

\end{thebibliography}

\end{document}
